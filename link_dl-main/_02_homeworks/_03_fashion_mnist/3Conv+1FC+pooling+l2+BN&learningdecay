digraph {
	graph [size="14.85,14.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	10741113904 [label="
 (1, 10)" fillcolor=darkolivegreen1]
	10824161968 [label=SoftmaxBackward0]
	10824161200 -> 10824161968
	10824161200 [label=AddmmBackward0]
	10824163312 -> 10824161200
	10741698928 [label="fc2.bias
 (10)" fillcolor=lightblue]
	10741698928 -> 10824163312
	10824163312 [label=AccumulateGrad]
	10824162736 -> 10824161200
	10824162736 [label=ReluBackward0]
	10824162880 -> 10824162736
	10824162880 [label=NativeBatchNormBackward0]
	10824162544 -> 10824162880
	10824162544 [label=AddmmBackward0]
	10824170176 -> 10824162544
	10823831280 [label="fc1.bias
 (128)" fillcolor=lightblue]
	10823831280 -> 10824170176
	10824170176 [label=AccumulateGrad]
	10834953696 -> 10824162544
	10834953696 [label=ReshapeAliasBackward0]
	10834952688 -> 10834953696
	10834952688 [label=ReluBackward0]
	10834957968 -> 10834952688
	10834957968 [label=NativeBatchNormBackward0]
	10834964160 -> 10834957968
	10834964160 [label=ConvolutionBackward0]
	10834965216 -> 10834964160
	10834965216 [label=MaxPool2DWithIndicesBackward0]
	10834959072 -> 10834965216
	10834959072 [label=ReluBackward0]
	10834960896 -> 10834959072
	10834960896 [label=ConvolutionBackward0]
	10834968240 -> 10834960896
	10834968240 [label=ReluBackward0]
	10834956768 -> 10834968240
	10834956768 [label=NativeBatchNormBackward0]
	10834954224 -> 10834956768
	10834954224 [label=ConvolutionBackward0]
	10834960800 -> 10834954224
	10880785904 [label="conv1.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	10880785904 -> 10834960800
	10834960800 [label=AccumulateGrad]
	10834958880 -> 10834954224
	10880936720 [label="conv1.bias
 (64)" fillcolor=lightblue]
	10880936720 -> 10834958880
	10834958880 [label=AccumulateGrad]
	10834960368 -> 10834956768
	10822725168 [label="bn1.weight
 (64)" fillcolor=lightblue]
	10822725168 -> 10834960368
	10834960368 [label=AccumulateGrad]
	10834954272 -> 10834956768
	10880072368 [label="bn1.bias
 (64)" fillcolor=lightblue]
	10880072368 -> 10834954272
	10834954272 [label=AccumulateGrad]
	10834959600 -> 10834960896
	10822773760 [label="conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	10822773760 -> 10834959600
	10834959600 [label=AccumulateGrad]
	10834966224 -> 10834960896
	10741696288 [label="conv2.bias
 (64)" fillcolor=lightblue]
	10741696288 -> 10834966224
	10834966224 [label=AccumulateGrad]
	10834966272 -> 10834964160
	10818147312 [label="conv3.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	10818147312 -> 10834966272
	10834966272 [label=AccumulateGrad]
	10834964352 -> 10834964160
	10741705808 [label="conv3.bias
 (128)" fillcolor=lightblue]
	10741705808 -> 10834964352
	10834964352 [label=AccumulateGrad]
	10834962528 -> 10834957968
	10741706448 [label="bn2.weight
 (128)" fillcolor=lightblue]
	10741706448 -> 10834962528
	10834962528 [label=AccumulateGrad]
	10834960752 -> 10834957968
	10741706768 [label="bn2.bias
 (128)" fillcolor=lightblue]
	10741706768 -> 10834960752
	10834960752 [label=AccumulateGrad]
	10834962624 -> 10824162544
	10834962624 [label=TBackward0]
	10834957440 -> 10834962624
	10880783824 [label="fc1.weight
 (128, 25088)" fillcolor=lightblue]
	10880783824 -> 10834957440
	10834957440 [label=AccumulateGrad]
	10824162448 -> 10824162880
	10741694528 [label="bn3.weight
 (128)" fillcolor=lightblue]
	10741694528 -> 10824162448
	10824162448 [label=AccumulateGrad]
	10824162208 -> 10824162880
	10741703728 [label="bn3.bias
 (128)" fillcolor=lightblue]
	10741703728 -> 10824162208
	10824162208 [label=AccumulateGrad]
	10824169888 -> 10824161200
	10824169888 [label=TBackward0]
	10824170704 -> 10824169888
	10741696528 [label="fc2.weight
 (10, 128)" fillcolor=lightblue]
	10741696528 -> 10824170704
	10824170704 [label=AccumulateGrad]
	10824161968 -> 10741113904
}
